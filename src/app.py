# src/app.py

import streamlit as st
import json
import logging
import asyncio
from datetime import datetime
from typing import Dict, List, Any
import pandas as pd
from config import TWEETS_FILE
from gpt_analyzer import GPTAnalyzer

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TweetData:
    """Class to manage tweet data loading and basic operations."""
    
    def __init__(self, file_path: str):
        """Initialize with tweets data file."""
        self.tweets = self._load_tweets(file_path)
        self.authors = self._get_unique_authors()
        
    def _load_tweets(self, file_path: str) -> List[Dict]:
        """Load tweets from JSON file."""
        try:
            with open(file_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Error loading tweets: {e}")
            return []
            
    def _get_unique_authors(self) -> List[str]:
        """Get list of unique authors from tweets."""
        return sorted(list(set(tweet['author_id'] for tweet in self.tweets)))

    def get_author_tweets(self, author_id: str) -> List[Dict]:
        """Get all tweets from specific author."""
        return [tweet for tweet in self.tweets if tweet['author_id'] == author_id]

    def get_tweet_statistics(self, tweets: List[Dict]) -> Dict:
        """Calculate statistics for given tweets."""
        if not tweets:
            return {
                "total_tweets": 0,
                "total_engagement": 0,
                "avg_engagement": 0,
                "top_tweets": []
            }
            
        return {
            "total_tweets": len(tweets),
            "total_engagement": sum(
                tweet['metrics']['retweet_count'] + 
                tweet['metrics']['reply_count'] + 
                tweet['metrics']['like_count']
                for tweet in tweets
            ),
            "avg_engagement": sum(
                tweet['metrics']['retweet_count'] + 
                tweet['metrics']['reply_count'] + 
                tweet['metrics']['like_count']
                for tweet in tweets
            ) / len(tweets),
            "top_tweets": sorted(
                tweets,
                key=lambda x: (
                    x['metrics']['retweet_count'] + 
                    x['metrics']['reply_count'] + 
                    x['metrics']['like_count']
                ),
                reverse=True
            )[:5]
        }

def create_search_interface():
    """Create and return search interface elements."""
    st.markdown("### Search Tweets")
    
    # Main search input
    search_query = st.text_input(
        "Enter your search query:",
        placeholder="e.g., blockchain OR crypto OR 'Web3 development' -scam lang:en"
    )
    
    # Advanced search options
    with st.expander("Advanced Search Options"):
        col1, col2 = st.columns(2)
        
        with col1:
            date_from = st.date_input("From date", None)
            min_engagement = st.number_input(
                "Minimum engagement", 
                min_value=0, 
                value=0
            )
            
        with col2:
            date_to = st.date_input("To date", None)
            author = st.text_input("Author")
    
    # Create filters dictionary
    filters = {}
    if date_from:
        filters['date_from'] = date_from.strftime('%Y-%m-%d')
    if date_to:
        filters['date_to'] = date_to.strftime('%Y-%m-%d')
    if min_engagement > 0:
        filters['min_engagement'] = min_engagement
    if author:
        filters['author'] = author
        
    return search_query, filters

def show_search_results(matches: List[Dict]):
    """Display search results."""
    st.markdown(f"### Found {len(matches)} matching tweets")
    
    for match in matches:
        with st.container():
            st.markdown(f"**@{match['author_id']}**")
            st.markdown(match['text'])
            
            # Show relevance and explanation if available
            if 'relevance_score' in match:
                st.markdown(f"*Relevance Score:* {match['relevance_score']:.2f}")
            if 'relevance_explanation' in match:
                st.markdown(f"*Why relevant:* {match['relevance_explanation']}")
            
            # Show metrics
            st.markdown(f"""
                *Posted on: {match['created_at']}* | 
                üí¨ {match['metrics']['reply_count']} | 
                üîÑ {match['metrics']['retweet_count']} | 
                ‚ù§Ô∏è {match['metrics']['like_count']}
            """)
            st.markdown("---")

def show_content_analysis(analysis: Dict):
    col1, col2 = st.columns(2)
    
    with col1:
        # Popular Topics
        st.markdown("### Popular Topics")
        if analysis.get("topics"):
            topics_df = pd.DataFrame(analysis["topics"][:5])
            st.dataframe(topics_df[["name", "count", "importance"]])
        
        # Keywords
        st.markdown("### Top Keywords")
        if analysis.get("trends", {}).get("keywords"):
            st.markdown(", ".join(analysis["trends"]["keywords"][:5]))
        
        # Sentiment Overview
        st.markdown("### Sentiment Overview")
        if analysis.get("sentiment"):
            sentiment = analysis["sentiment"]["overall_sentiment"]
            st.markdown(f"**Score:** {sentiment['score']:.2f}")
            st.markdown(f"**Summary:** {sentiment['summary']}")
        
        # Sentiment Breakdown
        st.markdown("### Sentiment Breakdown")
        sentiment_stats = analysis.get("sentiment", {}).get('sentiment_distribution', {
            'positive': 0,
            'negative': 0,
            'neutral': 0
        })
        
        col_sent1, col_sent2, col_sent3 = st.columns(3)
        
        with col_sent1:
            st.metric("Positive Tweets", sentiment_stats.get('positive', 0))
        
        with col_sent2:
            st.metric("Negative Tweets", sentiment_stats.get('negative', 0))
        
        with col_sent3:
            st.metric("Neutral Tweets", sentiment_stats.get('neutral', 0))
    
    with col2:
        # Key Discussions
        st.markdown("### Active Discussions")
        if analysis.get("key_discussions"):
            for discussion in analysis["key_discussions"][:5]:
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∞ –∑ –∫—ñ–ª—å–∫–æ–º–∞ fallback-–≤–∞—Ä—ñ–∞–Ω—Ç–∞–º–∏
                author = (
                    discussion.get('author') or 
                    discussion.get('author_id') or 
                    'Unknown'
                )
                st.markdown(f"**Author:** @{author}")
                st.markdown(f"**Tweet:** {discussion['tweet_text']}")
                st.markdown(f"*Importance:* {discussion['importance']}/10")
                st.markdown("---")

def show_statistics(tweet_data: TweetData, tweets: List[Dict]):
    with st.sidebar:
        st.header("Author Statistics Filters")
        
        # –í–∏–±—ñ—Ä –∞–≤—Ç–æ—Ä–∞ –∑ –Ω–∞—è–≤–Ω–∏—Ö —É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ—à—É–∫—É
        selected_author = st.selectbox(
            "Select Author",
            options=tweet_data.authors,
            format_func=lambda x: f"@{x}"
        )
        
        # –§—ñ–ª—å—Ç—Ä –ø–æ –¥–∞—Ç—ñ
        date_range = st.date_input(
            "Filter date range", 
            value=None,
            help="Select start and end date for tweets"
        )
        
        # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥ –∑–∞–ª—É—á–µ–Ω–æ—Å—Ç—ñ
        min_engagement = st.number_input(
            "Minimum total engagement", 
            min_value=0, 
            value=0,
            help="Filter tweets with engagement above this threshold"
        )
        
        # –í–∞—Ä—ñ–∞–Ω—Ç–∏ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
        sort_options = {
            "Total Engagement": lambda t: (t['metrics']['retweet_count'] + 
                                           t['metrics']['reply_count'] + 
                                           t['metrics']['like_count']),
            "Retweets": lambda t: t['metrics']['retweet_count'],
            "Likes": lambda t: t['metrics']['like_count'],
            "Replies": lambda t: t['metrics']['reply_count']
        }
        
        # –í–∏–±—ñ—Ä —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
        sort_by = st.selectbox(
            "Sort tweets by", 
            options=list(sort_options.keys())
        )
        
        # –ö–Ω–æ–ø–∫–∞ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤
        apply_filters = st.button("Apply Filters")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —á–∏ –æ–±—Ä–∞–Ω–æ –∞–≤—Ç–æ—Ä–∞
    if not selected_author:
        st.warning("Please select an author to view statistics")
        return
    
    # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–≤—ñ—Ç—ñ–≤
    if apply_filters or selected_author:
        # –§—ñ–ª—å—Ç—Ä –ø–æ –∞–≤—Ç–æ—Ä—É
        author_tweets = [t for t in tweets if t['author_id'] == selected_author]
        
        # –§—ñ–ª—å—Ç—Ä –ø–æ –¥–∞—Ç—ñ
        if date_range and len(date_range) == 2:
            start_date, end_date = date_range
            author_tweets = [
                t for t in author_tweets 
                if start_date <= datetime.strptime(t['created_at'], '%Y-%m-%dT%H:%M:%S').date() <= end_date
            ]
        
        # –§—ñ–ª—å—Ç—Ä –ø–æ –∑–∞–ª—É—á–µ–Ω–æ—Å—Ç—ñ
        author_tweets = [
            t for t in author_tweets
            if (t['metrics']['retweet_count'] + 
                t['metrics']['reply_count'] + 
                t['metrics']['like_count']) >= min_engagement
        ]
        
        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
        author_tweets = sorted(
            author_tweets, 
            key=sort_options[sort_by], 
            reverse=True
        )
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats = tweet_data.get_tweet_statistics(author_tweets)
        
        # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### Author Metrics")
            st.markdown(f"**Total Tweets:** {stats['total_tweets']}")
            st.markdown(f"**Total Engagement:** {stats['total_engagement']}")
            st.markdown(f"**Average Engagement:** {stats['avg_engagement']:.2f}")
        
        with col2:
            st.markdown("### Top Tweets")
            for tweet in stats['top_tweets']:
                total_engagement = (
                    tweet['metrics']['retweet_count'] +
                    tweet['metrics']['reply_count'] +
                    tweet['metrics']['like_count']
                )
                st.markdown(f"**Tweet:** {tweet['text']}")
                st.markdown(f"*Total Engagement:* {total_engagement}")
                st.markdown("---")
        
        # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞, —è–∫—â–æ –Ω–µ–º–∞—î —Ç–≤—ñ—Ç—ñ–≤ –ø—ñ—Å–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó
        if not author_tweets:
            st.info("No tweets found matching the selected filters")

async def main():
    st.set_page_config(page_title="Twitter Analysis Tool", layout="wide")
    st.title("Twitter Analysis Tool")
    
    # Initialize components
    tweet_data = TweetData(TWEETS_FILE)
    analyzer = GPTAnalyzer()
    
    # Search interface
    search_query, filters = create_search_interface()
    
    if search_query:
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Å—Ç–∞—Ç—É—Å—É
        status_container = st.empty()
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä –æ–¥—Ä–∞–∑—É
        progress_bar = st.progress(0)

        try:
            # –ü–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤ –∑ –ø—Ä–æ–≥—Ä–µ—Å–æ–º –≤—ñ–¥—Ä–∞–∑—É
            with st.spinner(f'Searching tweets...'):
                progress_bar.progress(10)  # –ü—Ä–æ–≥—Ä–µ—Å –æ–¥—Ä–∞–∑—É –ø—ñ—Å–ª—è —Å—Ç–∞—Ä—Ç—É
                search_results = await analyzer.search_tweets(
                    tweet_data.tweets, 
                    search_query, 
                    filters
                )
            
            if search_results.get("error"):
                st.error(f"Search error: {search_results['error']}")
                progress_bar.empty()
                return
            
            matched_tweets = search_results.get("matches", [])
            
            if not matched_tweets:
                st.warning("No tweets found matching your criteria.")
                progress_bar.empty()
                return
            
            # –û–Ω–æ–≤–ª—é—î–º–æ spinner –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Ç–≤—ñ—Ç—ñ–≤
            with st.spinner(f'Searching tweets... Found {len(matched_tweets)} tweets. Analyzing content...'):
                progress_bar.progress(30)  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π —Ä—ñ–≤–µ–Ω—å –ø—Ä–æ–≥—Ä–µ—Å—É

            # –ê–Ω–∞–ª—ñ–∑ –∫–æ–Ω—Ç–µ–Ω—Ç—É
            with st.spinner('Performing content analysis...'):
                progress_bar.progress(50)
                content_analysis = await analyzer.analyze_content(matched_tweets)
                
                progress_bar.progress(70)
                sentiment_analysis = await analyzer.analyze_sentiment(matched_tweets)
                
                progress_bar.progress(90)
            
            # –û—á–∏—â–∞—î–º–æ —Å—Ç–∞—Ç—É—Å-–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            status_container.empty()
            
            # –ó–∞–≤–µ—Ä—à—É—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä
            progress_bar.progress(100)
            
            # Combine analyses
            full_analysis = {
                "topics": content_analysis.get('topics', []),
                "key_discussions": content_analysis.get('key_discussions', []),
                "trends": content_analysis.get('trends', {}),
                "sentiment": {
                    **sentiment_analysis,
                    "sentiment_distribution": sentiment_analysis.get('sentiment_distribution', {
                        'positive': 0,
                        'negative': 0,
                        'neutral': 0
                    })
                }
            }
            
            # Display results in tabs
            tab1, tab2, tab3 = st.tabs(
                ["Search Results", "Content Analysis", "Statistics"]
            )
            
            with tab1:
                show_search_results(matched_tweets)
                
            with tab2:
                show_content_analysis(full_analysis)
                
            with tab3:
                matched_authors = list(set(tweet['author_id'] for tweet in matched_tweets))
                tweet_data = TweetData(TWEETS_FILE)
                tweet_data.authors = matched_authors
                show_statistics(tweet_data, matched_tweets)
            
            # –í–∏–¥–∞–ª—è—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
            progress_bar.empty()
            
        except Exception as e:
            logger.error(f"Analysis error: {e}")
            status_container.error("An error occurred during analysis. Please try again.")
            progress_bar.empty()

if __name__ == "__main__":
    asyncio.run(main())