# src/app.py
import logging
import streamlit as st
from src.collector import TwitterCollector
from src.analyzer import TweetAnalyzer
from src.database import TweetDatabase
from src.exceptions import NetworkError, RateLimitError, ParsingError
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    filename='twitter_analyzer.log'  # —Ñ–∞–π–ª –¥–ª—è –ª–æ–≥—ñ–≤
)
logger = logging.getLogger(__name__)

def init_components():
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ –ø—Ä–æ–≥—Ä–∞–º–∏"""
    return TwitterCollector(), TweetAnalyzer(), TweetDatabase()

def main():
    st.title("Twitter Analyzer üìä")

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
    collector, analyzer, db = init_components()
    
    # Sidebar
    st.sidebar.header("–ü—Ä–æ –ø—Ä–æ–≥—Ä–∞–º—É")
    st.sidebar.info(
        "–¶–µ–π —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–æ–∑–≤–æ–ª—è—î:\n"
        "- –ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç —Ç–≤—ñ—Ç—ñ–≤\n"
        "- –í–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –ø–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏\n"
        "- –ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –∑–≤—ñ—Ç–∏"
    )

    # –î–æ–¥–∞—î–º–æ —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫ –≤ sidebar
    st.sidebar.markdown("---")

    # –Ü—Å—Ç–æ—Ä—ñ—è –ø–æ—à—É–∫—ñ–≤ –≤ sidebar
    st.sidebar.header("–Ü—Å—Ç–æ—Ä—ñ—è –ø–æ—à—É–∫—ñ–≤")
    previous_queries = db.get_all_queries()
    if previous_queries:
        selected_query = st.sidebar.selectbox(
            "–í–∏–±–µ—Ä—ñ—Ç—å –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –∑–∞–ø–∏—Ç",
            [""] + previous_queries,
            index=0
        )
    else:
        st.sidebar.info("–Ü—Å—Ç–æ—Ä—ñ—è –ø–æ—à—É–∫—ñ–≤ –ø–æ—Ä–æ–∂–Ω—è")

    analysis = {}
    
    # –î–æ–¥–∞—î–º–æ —Å–µ–∫—Ü—ñ—é –ø–æ—à—É–∫—É –ø–µ—Ä–µ–¥ –≤–∫–ª–∞–¥–∫–∞–º–∏
    st.header("üîç –ü–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤")
    col1, col2 = st.columns([3, 1])
    with col1:
        st.write("–¢–æ–ø-5 –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤:")
        for keyword_data in analysis.get('trending_topics', [])[:5]:
            st.write(f"- {keyword_data['keyword']} (–ö–æ–Ω—Ç–µ–∫—Å—Ç: {keyword_data['context']})")
            st.caption(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å: {keyword_data['count']}, –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –±–∞–ª: {keyword_data['semantic_score']}")
    with col2:
        max_results = st.slider(
            "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–≤—ñ—Ç—ñ–≤",
            min_value=5,
            max_value=25,
            value=10,
            key="max_results_slider_main"
        )

    query = st.text_input(
        "–í–≤–µ–¥—ñ—Ç—å –ø–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç",
        help="–í–≤–µ–¥—ñ—Ç—å –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ—à—É–∫—É —Ç–≤—ñ—Ç—ñ–≤"
    )

    max_results = st.slider(
        "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–≤—ñ—Ç—ñ–≤",
        min_value=5,
        max_value=25,
        value=10,
        key="max_results_slider_search"
    )

    if st.button("–ü–æ—à—É–∫", type="primary"):
        if query:
            # –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à
            if db.is_cache_valid(query):
                result = db.get_tweets_by_query(query)
                st.info(f"–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–µ—à–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ (–¥—ñ–π—Å–Ω—ñ –¥–æ {result['cached_until']})")
                st.session_state['current_tweets'] = result['tweets']
                st.session_state['data_source'] = '–ö–µ—à'
                st.session_state['last_updated'] = result['last_updated']

                # –ê–Ω–∞–ª—ñ–∑ –∫–µ—à–æ–≤–∞–Ω–∏—Ö —Ç–≤—ñ—Ç—ñ–≤
                analysis = analyzer.analyze_text_content(result['tweets'], max_results)
            else:
                # –Ø–∫—â–æ –∫–µ—à –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π, —Ä–æ–±–∏–º–æ –Ω–æ–≤–∏–π –∑–∞–ø–∏—Ç
                tweets = collector.search_tweets(query, max_results)
                
                if tweets:
                    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ç–≤—ñ—Ç–∏
                    analysis = analyzer.analyze_text_content(tweets, max_results)
                    
                    st.subheader("üîë –¢–æ–ø-5 –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤")
                    for keyword_data in analysis.get('trending_keywords', [])[:5]:
                        st.write(f"- {keyword_data['keyword']}")
                        st.caption(keyword_data.get('context', 'Trend in crypto domain'))
                    
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–≤—ñ—Ç–∏ –≤ —Å–µ—Å—ñ—é
                    st.session_state['current_tweets'] = tweets
                    st.session_state['data_source'] = 'API'
                    st.session_state['last_updated'] = datetime.now().isoformat()
        else:
            st.error("–í–≤–µ–¥—ñ—Ç—å –ø–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç")
    
    # –û—Å–Ω–æ–≤–Ω—ñ –≤–∫–ª–∞–¥–∫–∏
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìù –ê–Ω–∞–ª—ñ–∑ —Ç–µ–∫—Å—Ç—É", 
        "üîç –ü–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏",
        "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
        "üß† Sentiment –ê–Ω–∞–ª—ñ–∑"
    ])
        
    # –í–∫–ª–∞–¥–∫–∞ 1: –ê–Ω–∞–ª—ñ–∑ —Ç–µ–∫—Å—Ç—É
    with tab1:
        st.header("–ê–Ω–∞–ª—ñ–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É —Ç–≤—ñ—Ç—ñ–≤")
        if 'current_tweets' in st.session_state:
            tweets = st.session_state['current_tweets']
            
            # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
            analysis = analyzer.analyze_text_content(tweets, max_results)
            
            # –°–µ–∫—Ü—ñ—è 1: –ü–æ–ø—É–ª—è—Ä–Ω—ñ —Ç–µ–º–∏
            st.subheader("üìà –¢–æ–ø-5 –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö —Ç–µ–º")
            for topic in analysis['popular_phrases'][:5]:
                st.write(f"#{topic['topic']} (–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å: {topic['significance']})")
            
            # –°–µ–∫—Ü—ñ—è 2: –¢—Ä–µ–Ω–¥–∏ —Ç–∞ –æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è
            st.subheader("üí¨ –¢–æ–ø-5 –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ —Ç–∞ –∞–∫—Ç–∏–≤–Ω–∏—Ö –æ–±–≥–æ–≤–æ—Ä–µ–Ω—å")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("–¢–æ–ø-5 –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤:")
                for word, increase in analysis['trending_topics'][:5]:
                    st.write(f"- {word}: +{increase} –∑–≥–∞–¥—É–≤–∞–Ω—å")
            
            with col2:
                st.write("–¢–æ–ø-5 –∞–∫—Ç–∏–≤–Ω–∏—Ö –æ–±–≥–æ–≤–æ—Ä–µ–Ω—å:")
                for disc in analysis['active_discussions'][:5]:
                    with st.expander(f"–¢–≤—ñ—Ç –∑ {disc['replies']} –≤—ñ–¥–ø–æ–≤—ñ–¥—è–º–∏"):
                        st.write(disc['tweet'])
                        st.caption(f"–°—Ç–≤–æ—Ä–µ–Ω–æ: {disc['created_at']}")
            
            # –°–µ–∫—Ü—ñ—è 3: –ü–æ—à—É–∫ –ø–æ —Ç–µ–∫—Å—Ç—É
            st.subheader("üîç –ü–æ—à—É–∫ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–∏–º –¥–∞–Ω–∏–º")
            search_col1, search_col2 = st.columns([3, 1])
            with search_col1:
                search_text = st.text_input("–í–≤–µ–¥—ñ—Ç—å —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ—à—É–∫—É", key="text_search")
            with search_col2:
                search_type = st.selectbox(
                    "–¢–∏–ø –ø–æ—à—É–∫—É",
                    ["–¢–æ—á–Ω–∏–π –∑–±—ñ–≥", "–ß–∞—Å—Ç–∫–æ–≤–∏–π –∑–±—ñ–≥", "–ó–∞ —Ñ—Ä–∞–∑–æ—é"]
                )
            
            if search_text:
                search_results = analyzer.search_in_tweets(tweets, search_text, search_type)
                if search_results:
                    st.write(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(search_results)} —Ç–≤—ñ—Ç—ñ–≤:")
                    for tweet in search_results:
                        with st.expander(f"–¢–≤—ñ—Ç –≤—ñ–¥ {tweet['created_at']}"):
                            st.write(tweet['text'])
                            st.caption(f"–ê–≤—Ç–æ—Ä: {tweet['author_id']}")
                else:
                    st.warning("–ó–∞ –≤–∞—à–∏–º –∑–∞–ø–∏—Ç–æ–º –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            
        else:
            st.info("–°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤")
    
    # –í–∫–ª–∞–¥–∫–∞ 2: –ü–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
    with tab2:
        st.header("–ü–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏")
        if 'current_tweets' in st.session_state:
            tweets = st.session_state['current_tweets']
            
            # –í–∏–±—ñ—Ä —Ç–∏–ø—É –ø–æ—à—É–∫—É
            search_type = st.radio(
                "–û–±–µ—Ä—ñ—Ç—å —Ç–∏–ø –ø–æ—à—É–∫—É:",
                ["–ü–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤", "–ü–æ—à—É–∫ –∞–≤—Ç–æ—Ä—ñ–≤"]
            )
            
            # –ü–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤
            if search_type == "–ü–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤":
                st.subheader("üîç –ü–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤ –∑–∞ —Ç–µ–º–æ—é –∞–±–æ —Å–ª–æ–≤–æ–º")
                search_query = st.text_input("–í–≤–µ–¥—ñ—Ç—å —Ç–µ–º—É –∞–±–æ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ—à—É–∫—É")
                if search_query:
                    matching_tweets = analyzer.search_by_keyword(tweets, search_query)
                    st.write(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(matching_tweets)} —Ç–≤—ñ—Ç—ñ–≤")
                    for tweet in matching_tweets:
                        with st.expander(f"–¢–≤—ñ—Ç –≤—ñ–¥ {tweet['created_at']}"):
                            st.write(tweet['text'])
                            st.caption(f"–ê–≤—Ç–æ—Ä: {tweet['author_id']}")
                            metrics = tweet['metrics']
                            st.caption(
                                f"–í–∑–∞—î–º–æ–¥—ñ—ó: "
                                f"üëç {metrics.get('like_count', 0)} –ª–∞–π–∫—ñ–≤, "
                                f"üîÑ {metrics.get('retweet_count', 0)} —Ä–µ—Ç–≤—ñ—Ç—ñ–≤, "
                                f"üí¨ {metrics.get('reply_count', 0)} –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π"
                            )
            
            # –ü–æ—à—É–∫ –∞–≤—Ç–æ—Ä—ñ–≤
            else:
                st.subheader("üë• –ü–æ—à—É–∫ –∞–≤—Ç–æ—Ä—ñ–≤ –∑–∞ —Ç–µ–º–æ—é")
                topic = st.text_input("–í–≤–µ–¥—ñ—Ç—å —Ç–µ–º—É –∞–±–æ —Ñ—Ä–∞–∑—É")
                if topic:
                    authors = analyzer.find_users_by_topic(tweets, topic)
                    st.write(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(authors)} –∞–≤—Ç–æ—Ä—ñ–≤")
                    
                    # –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ –ø–æ–∫–∞–∑—É—î–º–æ –π–æ–≥–æ —Ç–≤—ñ—Ç–∏ –Ω–∞ —Ü—é —Ç–µ–º—É
                    for author in authors:
                        with st.expander(f"–ê–≤—Ç–æ—Ä: {author}"):
                            author_tweets = [t for t in tweets if t['author_id'] == author and topic.lower() in t['text'].lower()]
                            st.write(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–≤—ñ—Ç—ñ–≤ –Ω–∞ —Ü—é —Ç–µ–º—É: {len(author_tweets)}")
                            for tweet in author_tweets:
                                st.write(f"- {tweet['text']}")
                                st.caption(f"–°—Ç–≤–æ—Ä–µ–Ω–æ: {tweet['created_at']}")
                            
        else:
            st.info("–°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤")
    
    # –í–∫–ª–∞–¥–∫–∞ 3: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    with tab3:
        st.header("–°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑")
        if 'current_tweets' in st.session_state:
            tweets = st.session_state['current_tweets']
            
            # –°–µ–∫—Ü—ñ—è 1: –ê–Ω–∞–ª—ñ–∑ –ø–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É
            st.subheader("üë§ –ê–Ω–∞–ª—ñ–∑ —Ç–≤—ñ—Ç—ñ–≤ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞")
            # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∞–≤—Ç–æ—Ä—ñ–≤
            authors = list(set(tweet['author_id'] for tweet in tweets))
            selected_author = st.selectbox(
                "–í–∏–±–µ—Ä—ñ—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞",
                authors
            )
            
            if selected_author:
                metric = st.selectbox(
                    "–í–∏–±–µ—Ä—ñ—Ç—å –º–µ—Ç—Ä–∏–∫—É",
                    ['retweet_count', 'reply_count', 'like_count', 'quote_count'],
                    format_func=lambda x: {
                        'retweet_count': '–†–µ—Ç–≤—ñ—Ç–∏',
                        'reply_count': '–í—ñ–¥–ø–æ–≤—ñ–¥—ñ',
                        'like_count': '–õ–∞–π–∫–∏',
                        'quote_count': '–¶–∏—Ç—É–≤–∞–Ω–Ω—è'
                    }[x]
                )
                
                # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–æ–ø —Ç–≤—ñ—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
                user_tweets = [t for t in tweets if t['author_id'] == selected_author]
                sorted_tweets = sorted(
                    user_tweets,
                    key=lambda x: x['metrics'].get(metric, 0),
                    reverse=True
                )
                
                st.write(f"–¢–æ–ø —Ç–≤—ñ—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—é {metric}:")
                for tweet in sorted_tweets[:5]:
                    with st.expander(f"{metric}: {tweet['metrics'].get(metric, 0)}"):
                        st.write(tweet['text'])
                        st.caption(f"–°—Ç–≤–æ—Ä–µ–Ω–æ: {tweet['created_at']}")
            
            # –°–µ–∫—Ü—ñ—è 2: –ù–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à—ñ —Ç–≤—ñ—Ç–∏
            st.subheader("üî• –¢–≤—ñ—Ç–∏ –∑ –Ω–∞–π–±—ñ–ª—å—à–∏–º —ñ–Ω—Ç–µ—Ä–µ—Å–æ–º")
            
            interest_metric = st.radio(
                "–û–±–µ—Ä—ñ—Ç—å –ø–æ–∫–∞–∑–Ω–∏–∫ —ñ–Ω—Ç–µ—Ä–µ—Å—É",
                ["–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó", "–†–µ—Ç–≤—ñ—Ç–∏", "–í—ñ–¥–ø–æ–≤—ñ–¥—ñ", "–õ–∞–π–∫–∏"]
            )
            
            if interest_metric == "–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó":
                # –†–∞—Ö—É—î–º–æ —Å—É–º–∞—Ä–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤—Å—ñ—Ö –≤–∑–∞—î–º–æ–¥—ñ–π
                for tweet in tweets:
                    tweet['total_interactions'] = sum(
                        tweet['metrics'].get(m, 0) 
                        for m in ['retweet_count', 'reply_count', 'like_count', 'quote_count']
                    )
                sorted_tweets = sorted(
                    tweets,
                    key=lambda x: x['total_interactions'],
                    reverse=True
                )
                metric_name = 'total_interactions'
            else:
                metric_map = {
                    "–†–µ—Ç–≤—ñ—Ç–∏": "retweet_count",
                    "–í—ñ–¥–ø–æ–≤—ñ–¥—ñ": "reply_count",
                    "–õ–∞–π–∫–∏": "like_count"
                }
                sorted_tweets = sorted(
                    tweets,
                    key=lambda x: x['metrics'].get(metric_map[interest_metric], 0),
                    reverse=True
                )
                metric_name = metric_map[interest_metric]
            
            # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–æ–ø-10 —Ç–≤—ñ—Ç—ñ–≤
            st.write("–¢–æ–ø-10 —Ç–≤—ñ—Ç—ñ–≤ –∑–∞ –æ–±—Ä–∞–Ω–∏–º –ø–æ–∫–∞–∑–Ω–∏–∫–æ–º:")
            for tweet in sorted_tweets[:10]:
                metric_value = (tweet['total_interactions'] 
                              if interest_metric == "–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó"
                              else tweet['metrics'].get(metric_map[interest_metric], 0))
                with st.expander(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∑–∞—î–º–æ–¥—ñ–π: {metric_value}"):
                    st.write(tweet['text'])
                    st.caption(f"–ê–≤—Ç–æ—Ä: {tweet['author_id']}")
                    st.caption(f"–°—Ç–≤–æ—Ä–µ–Ω–æ: {tweet['created_at']}")
                    st.caption(
                        f"–î–µ—Ç–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: "
                        f"üîÑ {tweet['metrics'].get('retweet_count', 0)} —Ä–µ—Ç–≤—ñ—Ç—ñ–≤, "
                        f"üí¨ {tweet['metrics'].get('reply_count', 0)} –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π, "
                        f"üëç {tweet['metrics'].get('like_count', 0)} –ª–∞–π–∫—ñ–≤, "
                        f"üìù {tweet['metrics'].get('quote_count', 0)} —Ü–∏—Ç—É–≤–∞–Ω—å"
                    )
            
        else:
            st.info("–°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤")

    # –í–∫–ª–∞–¥–∫–∞ 4: –ü–æ–≥–ª–∏–±–ª–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç–≤—ñ—Ç—ñ–≤
    with tab4:
        st.header("–ü–æ–≥–ª–∏–±–ª–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç–≤—ñ—Ç—ñ–≤")
        if 'current_tweets' in st.session_state:
            tweets = st.session_state['current_tweets']
            
            # –í–∏–∫–æ–Ω—É—î–º–æ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
            advanced_analysis = analyzer.advanced_tweet_analysis(tweets)
            
            # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É sentiment
            st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Sentiment")
            stats = advanced_analysis['sentiment_stats']
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("–ü–æ–∑–∏—Ç–∏–≤–Ω—ñ", stats['positive_count'])
            with col2:
                st.metric("–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ñ", stats['neutral_count'])
            with col3:
                st.metric("–ù–µ–≥–∞—Ç–∏–≤–Ω—ñ", stats['negative_count'])
            
            # –¢–æ–ø –µ–º–æ—Ü—ñ–π
            st.subheader("üòÄ –¢–æ–ø –µ–º–æ—Ü—ñ–π")
            for emotion, count in advanced_analysis['top_emotions']:
                st.write(f"{emotion}: {count}")
            
            # –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç—Ä–µ–Ω–¥—ñ–≤
            st.subheader("üîç –ö–ª—é—á–æ–≤—ñ —Ç—Ä–µ–Ω–¥–∏")
            for trend in analysis.get('significant_trends', []):
                st.markdown(f"**{trend['title']}**")
                st.write(f"*–ö–æ–Ω—Ç–µ–∫—Å—Ç*: {trend['context']}")
                st.caption(f"*–ü–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏–π –≤–ø–ª–∏–≤*: {trend['potential_impact']}")
        else:
            st.info("–°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø–æ—à—É–∫ —Ç–≤—ñ—Ç—ñ–≤")

if __name__ == "__main__":
    st.set_page_config(
        page_title="Twitter Analyzer",
        page_icon="üìä",
        layout="wide"
    )
    main()